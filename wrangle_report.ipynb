{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b92aa889",
   "metadata": {},
   "source": [
    "# Data Wrangling Report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a8ef0c",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "> This report contains a detailed description of the efforts made in wrangling the WeRateDogs Twitter archive data, Image Prediction data, and supplementary tweet data obtained via the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4decdacc",
   "metadata": {},
   "source": [
    "## Step 1: Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe1654c",
   "metadata": {},
   "source": [
    "### WeRateDogs Twitter Archive Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89c809b",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Directly download the WeRateDogs Twitter archive data (twitter_archive_enhanced.csv).</li>\n",
    "    <li>Read the downloaded csv file as a pandas dataframe df_archive</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0483d",
   "metadata": {},
   "source": [
    "### Tweet Image Prediction Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b667c6",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Use the given url to download the tweet image prediction (image_predictions.tsv) via the Requests library.</li>\n",
    "    <li>Read the downloaded tsv file as a pandas dataframe df_image.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c3f34",
   "metadata": {},
   "source": [
    "### Additional Data From Twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918f9d3",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Get the tweet ids from the archive data.</li>\n",
    "    <li>Extract and store the API keys that will be used to query the data.</li>\n",
    "    <li>Authenticate and set access via the Tweepy library.</li>\n",
    "    <li>Use the Tweepy library to write the data into the tweet_json text file.</li>\n",
    "    <li>Read the data in the text file into a pandas dataframe</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e251a636",
   "metadata": {},
   "source": [
    "## Step 2: Data Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ee1d7",
   "metadata": {},
   "source": [
    "### Method Applied To All Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75463a28",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Use the dataframe shape attribute to get information on the number of observations and features.</li>\n",
    "    <li>Draw a random sample of 20 observations and visually assess.</li>\n",
    "    <li>Use the dataframe info method to get information on null values and datatype of each feature.</li>\n",
    "    <li>Combine the duplicated and sum methods to get information on the number of duplicated observations.</li>\n",
    "    <li>Use the describe method to obtain statistical information on the numerical features.</li>\n",
    "    <li>Use the value_counts and unique methods to further get information on categorical features.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb056d7",
   "metadata": {},
   "source": [
    "### Issues Identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ef6dee",
   "metadata": {},
   "source": [
    "#### Quality issues\n",
    "1. There are non null values in the retweeted_status_id column, indicating a retweet, this is not an original rating and goes against project instructions.\n",
    "\n",
    "2.  The data type of the tweet_id column of the enhanced twiteer archive dataset is integer and not string. \n",
    "\n",
    "3. The timestamp column of the enhanced twitter archive dataset is not a datetime object.\n",
    "\n",
    "4. There are missing values in the expanded_urls column of the enhanced twitter archive dataset that have not been handled.\n",
    "\n",
    "5. The tweet_id column in the image predictios dataset is in integer datatype and not string.\n",
    "\n",
    "6. Inconsistent representation of names in the p1,p2 and p3 columns of the image prediction dataset.\n",
    "\n",
    "7. The id column of the api data is not in string format.\n",
    "\n",
    "8. Relatively few number of unhandled missing values in the extended_entities, possibly_sensitive and possibly_sensitive_appealable column of the api data.\n",
    "\n",
    "9. Overwhelming number of missing values in the in_reply_to_status_id, in_reply_to_status_id_str, in_reply_to_user_id, in_reply_to_user_id_str, in_reply_to_screen_namegeo, coordinates, place, contributors, retweeted_status, quoted_status_id,quoted_status_id_str,quoted_status_permalink and quoted_status columns of the api data.\n",
    "\n",
    "10. The rating_denominator column of the archive dataset has an entry with a value of 0.\n",
    "\n",
    "11. The display_text_range column of the api data contains a list with two variables, the initial and final number of characters in the tweet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c97c7b3",
   "metadata": {},
   "source": [
    "#### Tidiness issues\n",
    "1. The id_str column is a duplicate of the id column in the api data.\n",
    "\n",
    "2. doggo, floofer, pupper, puppo columns in twitter_archive_enhanced.csv should be combined into a single column as this is one variable that identify the stage of dog.\n",
    "\n",
    "3. Information about one type of observational unit (tweets) is spread across three different files/dataframes. So these three dataframes should be merged as they are part of the same observational unit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ab9c0",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556a9ca1",
   "metadata": {},
   "source": [
    "> The following strategies were employed to handle the above quality and tidiness issues. Before cleaning, copies of the assessed dataframes will be made. These copies will be cleaned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54a4387",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "> Respective solutions to the quality issues in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08655fc",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Drop the rows in which the value of the retweeted_status_id column is not null.</li>\n",
    "    <li>Change the datatype of the tweet_id column in the archive dataset from integer to string.</li>\n",
    "    <li>Change the datatype of the timestamp column of the enhanced twitter archive dataset to datetime</li>\n",
    "    <li>So as not to lose the entire row, fill the missing values of the expanded_urls column of the enhanced twitter archive dataset with the string 'Missing'.</li>\n",
    "    <li>Change the datatype of the tweet_id column in the image predictios dataset from integer to string.</li>\n",
    "    <li>Split the values in the p1,p2,p3 columns of the image prediction dataset by underscore, then capitalize and join back together for a consistent representation.</li>\n",
    "    <li>Change the datatype of the id column of the twitter api data from integer to string, and rename to tweet_id for consistency with the other two dataframes.</li>\n",
    "    <li>Fill the missing values in the extended_entities column with the string 'Missing', and the missing values in the possibly_sensitive and possibly_sensitive_appealable columns with 0.0.</li>\n",
    "    <li>Drop all columns with up to 2000 missing values.</li>\n",
    "    <li>Drop the row with a rating denominator of 0</li>\n",
    "    <li>Create a new column display_text_length from the display_text_range column, by indexing the second element of the list. Then dropping the display_text_range column.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee5d5912",
   "metadata": {},
   "source": [
    "### Tidiness\n",
    "\n",
    "> Respective solutions to the tidiness issues in order."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff07f21",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li>Drop the id_str column of the api dataset.</li>\n",
    "    <li>Create a single column containing the stage of the dog, also accounting for multiple stages, and drop the rows without a dog stage to allow suitable analysis.</li>\n",
    "    <li>Merge the df_archive_clean, df_image_clean and df_tweets_clean into one master dataset.</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd5b1b3",
   "metadata": {},
   "source": [
    "At the end of our data wrangling efforts, we store the cleaned datasets in master files, to be used for analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
